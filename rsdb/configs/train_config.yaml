training:
  dataset_split:
    train_frac: 0.8
    random_state: 42
  shuffle_buffer_size: 1024
  batch_size: 4096
  epochs: 1000
  patience: 10
  min_delta: 0.001
  learning_rate_schedule:
    initial_learning_rate: 0.00066501
    decay_steps: 1000
    decay_rate: 0.5
  model_save_path: "trained_{model_name}_model"

tdlf:
  embedding_dim: 120
  dense_units: 64
  l2_reg: 0.000121
  time_bins: 20

fpmc:
  embedding_dim: 104
  l2_reg: 0.00066295
  learning_rate: 0.00022001
